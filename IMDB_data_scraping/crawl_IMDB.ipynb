{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n",
      "There may be some problems\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-23b542c6ea2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-23b542c6ea2c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(base_url)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# Run functions and adding multiple df into one csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-23b542c6ea2c>\u001b[0m in \u001b[0;36mget_content\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    115\u001b[0m                            \u001b[0;34m'st1_link'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mst1_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                            \u001b[0;34m'star2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstars2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                            \u001b[0;34m'st2_link'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mst2_links\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     })\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7354\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7356\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7358\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   7400\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7402\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def get_html(url):\n",
    "    try:\n",
    "        r = requests.get(url, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        r.endcodding = r.apparent_endconding\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"ERROR\"\n",
    "\n",
    "def get_content(url):\n",
    "    # Lists to store the scraped data in\n",
    "    names = []\n",
    "    years = []\n",
    "    runtimes = []\n",
    "    genres = []\n",
    "    imdb_ratings = []\n",
    "    metascores = []\n",
    "    votes = []\n",
    "    grosses = []\n",
    "    directors = []\n",
    "    dr_links = []\n",
    "    stars1 = []\n",
    "    st1_links = []\n",
    "    stars2 = []\n",
    "    st2_links = []\n",
    "\n",
    "\n",
    "    # Get the url to local \n",
    "    html = requests.get(url)\n",
    "    # Parse html test\n",
    "    html_soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    # Get the position of movies\n",
    "    movie_containers = html_soup.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "\n",
    "    # Extract data from individual movie container\n",
    "    for container in movie_containers:\n",
    "        # Using try except to avoid crawl stop\n",
    "        try:\n",
    "            # The name\n",
    "            name = container.h3.a.text\n",
    "            names.append(name)\n",
    "            # The year\n",
    "            year = container.h3.find('span', class_ = 'lister-item-year').text\n",
    "            years.append(year)\n",
    "            # The run time\n",
    "            runtime = container.p.find('span', class_ = 'runtime').text\n",
    "            runtimes.append(runtime)\n",
    "            # The genre\n",
    "            if container.p.find('span', class_ = 'genre') is not None:\n",
    "                genre = container.p.find('span', class_ = 'genre').text\n",
    "                genres.append(genre)\n",
    "            else:\n",
    "                genres.append('NA')\n",
    "            # The IMDB rating\n",
    "            imdb = float(container.strong.text)\n",
    "            imdb_ratings.append(imdb)\n",
    "            # The Metascore\n",
    "            # If the movie has Metascore, then extract:\n",
    "            if container.find('div', class_ = 'ratings-metascore') is not None:\n",
    "                m_score = container.find('span', class_ = 'metascore').text\n",
    "                metascores.append(int(m_score))\n",
    "            else:\n",
    "                metascores.append('NA')\n",
    "            # The number of votes\n",
    "            vote = container.find_all('span', attrs = {'name':'nv'})[0]['data-value']\n",
    "            votes.append(int(vote))\n",
    "            # The number of gross\n",
    "            # If the movie has Metascore, then extract:\n",
    "            if len(container.find_all('span', attrs = {'name':'nv'})) ==2 :\n",
    "                gross = container.find_all('span', attrs = {'name':'nv'})[1].text\n",
    "                grosses.append(gross)\n",
    "            else:\n",
    "                grosses.append('NA')\n",
    "            # The name of director\n",
    "            a = container.find_all('p', class_= '')[1]\n",
    "            dr_tag = a.find_all('a', attrs={'href': re.compile(\"dr\")})[0]\n",
    "            director = dr_tag.text\n",
    "            directors.append(director)\n",
    "            # The link of director\n",
    "            dr_link = dr_tag.get('href')\n",
    "            dr_links.append(dr_link)\n",
    "            # The name and link of star\n",
    "            st_tag1 = a.find_all('a', attrs={'href': re.compile(\"st\")})[0]\n",
    "            star1 = st_tag1.text\n",
    "            stars1.append(star1)\n",
    "            st1_link = st_tag1.get('href')\n",
    "            st1_links.append(st1_link)\n",
    "            \n",
    "            st_tag2 = a.find_all('a', attrs={'href': re.compile(\"st\")})[1]\n",
    "            star2 = st_tag2.text\n",
    "            stars2.append(star2)\n",
    "            st2_link = st_tag2.get('href')\n",
    "            st2_links.append(st2_link)\n",
    "            \n",
    "        except:\n",
    "            print(\"There may be some problems\")\n",
    "    \n",
    "    df = pd.DataFrame({'movie': names,\n",
    "                           'year': years,\n",
    "                           'runtime': runtimes,\n",
    "                           'genre': genres,\n",
    "                           'imdb': imdb_ratings,\n",
    "                           'metascore': metascores,\n",
    "                           'votes': votes,\n",
    "                           'gross': grosses,\n",
    "                           'director': directors,\n",
    "                           'dr_link': dr_links,\n",
    "                           'star1': stars1,\n",
    "                           'st1_link': st1_links,\n",
    "                           'star2': stars2,\n",
    "                           'st2_link': st2_links\n",
    "    })\n",
    "    return(df)\n",
    "\n",
    "def main(base_url):\n",
    "    url_list = []\n",
    "    # List all url should be crawled\n",
    "    for i in range(2008,2019):\n",
    "        url_list.append(base_url + str(i) + ',' + str(i) + '&title_type=feature')\n",
    "\n",
    "    # Run functions and adding multiple df into one csv\n",
    "    for url in url_list:\n",
    "        df = get_content(url)\n",
    "        df.to_csv(\"data.csv\", sep='\\t', encoding='utf-8',mode='a')\n",
    "        print('OK')\n",
    "    \n",
    "base_url = 'https://www.imdb.com/search/title?count=100&release_date='\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
